{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgQkU8Nc00_3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import argparse\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/optical_flow_RAFT/RAFT/core')\n",
        "from argparse import ArgumentParser\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from raft import RAFT\n",
        "from utils import flow_viz\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "def frame_preprocess(frame, device):\n",
        "    frame = torch.from_numpy(frame).permute(2, 0, 1).float()\n",
        "    frame = frame.unsqueeze(0)\n",
        "    frame = frame.to(device)\n",
        "    return frame\n",
        "\n",
        "def vizualize_flow(img, flo, save, counter, vid_number):\n",
        "    # permute the channels and change device is necessary\n",
        "    img = img[0].permute(1, 2, 0).cpu().numpy()\n",
        "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
        "    # map flow to rgb image\n",
        "    flo = flow_viz.flow_to_image(flo)\n",
        "    flo = cv2.cvtColor(flo, cv2.COLOR_RGB2BGR)\n",
        "    # flo = cv2.cvtColor(flo, cv2.COLOR_RGB2GRAY)\n",
        "    # out.write(flo)\n",
        "    # print(\"frame\", counter)\n",
        "    # concatenate, save and show images\n",
        "    # img_flo = np.concatenate([img, flo], axis=0)\n",
        "    if save:\n",
        "        cv2.imwrite(f\"/content/drive/MyDrive/AnomalyResearch/TrainOpticalFlow/Train{str(vid_number).zfill(3)}/frame_{str(counter+1).zfill(3)}.jpg\", flo)\n",
        "    # cv2_imshow(img_flo / 255.0)\n",
        "    k = cv2.waitKey(25) & 0xFF\n",
        "    if k == 27:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_cpu_model(model):\n",
        "    new_model = OrderedDict()\n",
        "    # get all layer's names from model\n",
        "    for name in model:\n",
        "        # create new name and update new model\n",
        "        new_name = name[7:]\n",
        "        new_model[new_name] = model[name]\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def inference(args):\n",
        "    # get the RAFT model\n",
        "    model = RAFT(args)\n",
        "    # load pretrained weights\n",
        "    pretrained_weights = torch.load(args.model)\n",
        "\n",
        "    save = args.save\n",
        "    vid_number = args.video_number\n",
        "    if save:\n",
        "        if not os.path.exists(f\"/content/drive/MyDrive/AnomalyResearch/TrainOpticalFlow/Train{str(vid_number).zfill(3)}\"):\n",
        "            os.mkdir(f\"/content/drive/MyDrive/AnomalyResearch/TrainOpticalFlow/Train{str(vid_number).zfill(3)}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        # parallel between available GPUs\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        # load the pretrained weights into model\n",
        "        model.load_state_dict(pretrained_weights)\n",
        "        model.to(device)\n",
        "        print(\"in device\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        # change key names for CPU runtime\n",
        "        pretrained_weights = get_cpu_model(pretrained_weights)\n",
        "        # load the pretrained weights into model\n",
        "        model.load_state_dict(pretrained_weights)\n",
        "\n",
        "    # change model's mode to evaluation\n",
        "    model.eval()\n",
        "\n",
        "    video_path = args.video\n",
        "    # capture the video and get the first frame\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame_1 = cap.read()\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # frame preprocessing\n",
        "    frame_1 = cv2.resize(frame_1, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "    frame_1 = frame_preprocess(frame_1, device)\n",
        "\n",
        "    counter = 0\n",
        "    # Define the codec and create VideoWriter object\n",
        "    with torch.no_grad():\n",
        "       for i in tqdm(range(length)):\n",
        "            # read the next frame\n",
        "            ret, frame_2 = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            # preprocessing\n",
        "            frame_2 = cv2.resize(frame_2, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "            frame_2 = frame_preprocess(frame_2, device)\n",
        "            # predict the flow\n",
        "            flow_low, flow_up = model(frame_1, frame_2, iters=args.iters, test_mode=True)\n",
        "            # transpose the flow output and convert it into numpy array\n",
        "            ret = vizualize_flow(frame_1, flow_up, save, counter, vid_number)\n",
        "            if not ret:\n",
        "                break\n",
        "            frame_1 = frame_2\n",
        "            counter += 1"
      ],
      "metadata": {
        "id": "6xIGgzMjYoRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_video_opencv(image_folder, video_name, fps, dataset_video=None):\n",
        "  if dataset_video:\n",
        "      os.remove(dataset_video)\n",
        "\n",
        "  images = [img for img in os.listdir(image_folder) if img.endswith(\".tif\")]\n",
        "  images.sort()\n",
        "  frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "  height, width, layers = frame.shape\n",
        "\n",
        "  video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
        "\n",
        "  for image in images:\n",
        "      video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "  video.release()\n",
        "\n",
        "def create_optical_flow(root_dir, video_name, fps, video_number, dataset_video=None):\n",
        "  create_video_opencv(root_dir, video_name, fps, dataset_video)\n",
        "\n",
        "  args = argparse.Namespace(\n",
        "      iters=12, \n",
        "      mixed_precision=False, \n",
        "      model='/content/drive/MyDrive/optical_flow_RAFT/models/raft-sintel.pth', \n",
        "      save=True, \n",
        "      small=False, \n",
        "      video=video_name,\n",
        "      video_number=video_number)\n",
        "  inference(args)"
      ],
      "metadata": {
        "id": "gJ451Tc-45sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 35):\n",
        "  video_path = (f\"/content/drive/MyDrive/AnomalyResearch/Train/Train{str(i).zfill(3)}/\")\n",
        "  create_optical_flow(video_path, \"test.avi\", 15, i)"
      ],
      "metadata": {
        "id": "WG4m8EyuDy-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}